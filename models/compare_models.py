#!/usr/bin/env python3
"""
Script de comparaÃ§Ã£o de modelos LLM para anÃ¡lise de CSV OpenVAS
Compara GPT-4o-mini vs modelos opensource (Groq: Llama 3.3, Mixtral)
"""
import os
import sys
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# Adiciona o diretÃ³rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent))

from src.tools.csv_analyzer import OpenVASCSVAnalyzer

load_dotenv()

# ConfiguraÃ§Ãµes dos modelos a serem testados
MODELS_CONFIG = {
    "Llama-3.3-70B": {
        "provider": "groq",
        "model": "llama-3.3-70b-versatile",
        "description": "Modelo opensource da Meta via Groq - 70B parÃ¢metros"
    },
    "Llama-3.1-8B": {
        "provider": "groq",
        "model": "llama-3.1-8b-instant",
        "description": "Modelo opensource da Meta via Groq - versÃ£o compacta e rÃ¡pida"
    },
    "Mixtral-8x7B": {
        "provider": "groq",
        "model": "mixtral-8x7b-32768",
        "description": "Modelo opensource da Mistral AI via Groq - Mixture of Experts"
    },
    "Gemma-2-9B": {
        "provider": "groq",
        "model": "gemma2-9b-it",
        "description": "Modelo opensource do Google via Groq - versÃ£o compacta"
    },
    "GPT-4o-mini": {
        "provider": "openai",
        "model": "gpt-4o-mini",
        "description": "Modelo proprietÃ¡rio da OpenAI - versÃ£o compacta e econÃ´mica"
    }
}

def run_analysis(csv_path: str, provider: str, model: str):
    """Executa anÃ¡lise com um modelo especÃ­fico e retorna resultado + tempo"""
    print(f"  âš™ï¸  Analisando com {model}...")
    
    start_time = time.time()
    
    try:
        analyzer = OpenVASCSVAnalyzer(llm_provider=provider, model_name=model)
        result = analyzer.analyze_csv_file(csv_path)
        
        elapsed_time = time.time() - start_time
        
        return {
            "success": True,
            "summary": result['summary'],
            "statistics": result['statistics'],
            "time": elapsed_time,
            "error": None
        }
    except Exception as e:
        elapsed_time = time.time() - start_time
        return {
            "success": False,
            "summary": None,
            "statistics": None,
            "time": elapsed_time,
            "error": str(e)
        }

def generate_comparison_markdown(results: dict, csv_filename: str):
    """Gera markdown com comparaÃ§Ã£o dos modelos"""
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    md_content = f"""# ComparaÃ§Ã£o de Modelos LLM para AnÃ¡lise de Vulnerabilidades

## ðŸ“Š RelatÃ³rio de ComparaÃ§Ã£o

**Data da AnÃ¡lise:** {timestamp}  
**Arquivo CSV Analisado:** `{csv_filename}`  
**Objetivo:** Comparar desempenho e qualidade de resposta entre modelos proprietÃ¡rios (OpenAI) e opensource (Groq)

---

## ðŸŽ¯ Modelos Testados

"""
    
    for model_name, config in MODELS_CONFIG.items():
        md_content += f"### {model_name}\n"
        md_content += f"- **Provider:** {config['provider'].upper()}\n"
        md_content += f"- **Modelo:** `{config['model']}`\n"
        md_content += f"- **DescriÃ§Ã£o:** {config['description']}\n"
        md_content += f"- **Custo:** {'Pago' if config['provider'] == 'openai' else 'âœ… Gratuito'}\n\n"
    
    md_content += "---\n\n## âš¡ Performance Comparativa\n\n"
    md_content += "| Modelo | Tempo de Resposta | Status |\n"
    md_content += "|--------|-------------------|--------|\n"
    
    for model_name, result in results.items():
        status = "âœ… Sucesso" if result['success'] else "âŒ Erro"
        time_str = f"{result['time']:.2f}s" if result['time'] else "N/A"
        md_content += f"| {model_name} | {time_str} | {status} |\n"
    
    md_content += "\n---\n\n## ðŸ“ˆ AnÃ¡lise EstatÃ­stica dos Dados\n\n"
    
    # Pega estatÃ­sticas do primeiro modelo bem-sucedido
    stats = None
    for result in results.values():
        if result['success'] and result['statistics']:
            stats = result['statistics']
            break
    
    if stats:
        md_content += f"""**Dados do CSV:**
- Total de Vulnerabilidades: {stats['total_vulnerabilities']}
- Hosts Ãšnicos Afetados: {stats['unique_hosts']}

**DistribuiÃ§Ã£o por Severidade:**
"""
        if 'by_severity' in stats:
            for severity, count in stats['by_severity'].items():
                md_content += f"- {severity}: {count}\n"
    
    md_content += "\n---\n\n## ðŸ¤– Respostas Comparativas dos Modelos\n\n"
    
    for model_name, result in results.items():
        md_content += f"### {model_name}\n\n"
        
        if result['success']:
            md_content += f"**â±ï¸ Tempo de Processamento:** {result['time']:.2f} segundos\n\n"
            md_content += "**ðŸ“ Resumo Gerado:**\n\n"
            md_content += "```\n"
            md_content += result['summary']
            md_content += "\n```\n\n"
        else:
            md_content += f"**âŒ Erro durante anÃ¡lise:**\n\n"
            md_content += f"```\n{result['error']}\n```\n\n"
        
        md_content += "---\n\n"
    
    # AnÃ¡lise comparativa
    md_content += "## ðŸ” AnÃ¡lise Comparativa\n\n"
    
    successful_results = {k: v for k, v in results.items() if v['success']}
    
    if len(successful_results) > 1:
        # Encontra o mais rÃ¡pido
        fastest = min(successful_results.items(), key=lambda x: x[1]['time'])
        slowest = max(successful_results.items(), key=lambda x: x[1]['time'])
        
        md_content += f"### âš¡ Velocidade\n\n"
        md_content += f"- **Mais RÃ¡pido:** {fastest[0]} ({fastest[1]['time']:.2f}s)\n"
        md_content += f"- **Mais Lento:** {slowest[0]} ({slowest[1]['time']:.2f}s)\n"
        md_content += f"- **DiferenÃ§a:** {slowest[1]['time'] - fastest[1]['time']:.2f}s ({((slowest[1]['time'] / fastest[1]['time']) - 1) * 100:.1f}% mais lento)\n\n"
    
    md_content += "### ðŸ’° Custo-BenefÃ­cio\n\n"
    md_content += "| Modelo | Custo | Performance | RecomendaÃ§Ã£o |\n"
    md_content += "|--------|-------|-------------|---------------|\n"
    
    for model_name, config in MODELS_CONFIG.items():
        if model_name in successful_results:
            result = successful_results[model_name]
            cost = "ðŸ’² Pago" if config['provider'] == 'openai' else "ðŸ†“ Gratuito"
            perf = "âš¡ RÃ¡pido" if result['time'] < 5 else "â±ï¸ Moderado" if result['time'] < 10 else "ðŸŒ Lento"
            
            if config['provider'] == 'groq':
                rec = "â­â­â­ Excelente para prototipagem e uso sem custos"
            else:
                rec = "â­â­ Bom mas requer crÃ©ditos API"
            
            md_content += f"| {model_name} | {cost} | {perf} | {rec} |\n"
    
    md_content += "\n---\n\n## ðŸŽ“ ConclusÃµes\n\n"
    
    md_content += """### Modelos Opensource (Groq)

**Vantagens:**
- âœ… **Totalmente gratuito** - Ideal para desenvolvimento e testes
- âœ… **Alta velocidade** - InferÃªncia otimizada em hardware especializado
- âœ… **Qualidade competitiva** - Resultados comparÃ¡veis aos modelos pagos
- âœ… **Sem limites de crÃ©dito** - Rate limits generosos

**Desvantagens:**
- âš ï¸ DependÃªncia de serviÃ§o terceiro (Groq)
- âš ï¸ Rate limits podem ser restritivos em produÃ§Ã£o de alta escala

### Modelos ProprietÃ¡rios (OpenAI)

**Vantagens:**
- âœ… **Estabilidade empresarial** - SLA e suporte profissional
- âœ… **Modelos de Ãºltima geraÃ§Ã£o** - Acesso aos modelos mais avanÃ§ados
- âœ… **Ecossistema robusto** - Ferramentas e integraÃ§Ãµes maduras

**Desvantagens:**
- âŒ **Custo por uso** - Cada requisiÃ§Ã£o consome crÃ©ditos
- âŒ **Requer cartÃ£o de crÃ©dito** - Barreira de entrada

### ðŸ’¡ RecomendaÃ§Ã£o Final

"""
    
    if successful_results:
        groq_models = [k for k, v in MODELS_CONFIG.items() if v['provider'] == 'groq' and k in successful_results]
        if groq_models:
            best_groq = min([(k, successful_results[k]['time']) for k in groq_models], key=lambda x: x[1])
            md_content += f"""Para anÃ¡lise de vulnerabilidades do OpenVAS, **recomendamos o uso de modelos opensource via Groq**, especialmente o **{best_groq[0]}**:

1. **Sem custos operacionais** - Elimina preocupaÃ§Ãµes com billing
2. **Performance adequada** - Tempo de resposta aceitÃ¡vel ({best_groq[1]:.2f}s)
3. **Qualidade suficiente** - Gera insights acionÃ¡veis e resumos executivos claros
4. **Escalabilidade inicial** - Permite validar o projeto antes de investir

**Considere migrar para OpenAI apenas se:**
- Necessitar SLA empresarial
- Escala de produÃ§Ã£o exceder rate limits do Groq
- Precisar de modelos especÃ­ficos nÃ£o disponÃ­veis em Groq

"""
    
    md_content += """---

## ðŸ“š ReferÃªncias

- **Groq API:** https://console.groq.com
- **OpenAI API:** https://platform.openai.com
- **Llama 3.3:** https://ai.meta.com/llama/
- **Mixtral:** https://mistral.ai/
- **Gemma:** https://ai.google.dev/gemma

---

*RelatÃ³rio gerado automaticamente pelo OpenVAS Agent - CSV Analysis Module*
"""
    
    return md_content

def main():
    print("ðŸ”’ ComparaÃ§Ã£o de Modelos LLM - OpenVAS CSV Analysis")
    print("=" * 70)
    
    # Verifica se existem CSVs
    csv_folder = Path("csv_reports")
    csv_files = [f for f in csv_folder.glob("*.csv") if f.name != "exemplo_scan.csv"]
    
    if not csv_files:
        print("âŒ Nenhum CSV encontrado em csv_reports/")
        print("ðŸ’¡ Use o openvas-speed.csv ou coloque seu prÃ³prio CSV")
        return
    
    # Usa o primeiro CSV encontrado
    csv_path = str(csv_files[0])
    csv_filename = csv_files[0].name
    
    print(f"\nðŸ“„ Analisando: {csv_filename}")
    print(f"ðŸ“Š Testando {len(MODELS_CONFIG)} modelos...\n")
    
    # Verifica API keys
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  OPENAI_API_KEY nÃ£o configurada - OpenAI serÃ¡ pulado")
    
    if not os.getenv("GROQ_API_KEY"):
        print("âŒ GROQ_API_KEY nÃ£o configurada - modelos Groq nÃ£o funcionarÃ£o")
        return
    
    # Executa anÃ¡lise com cada modelo
    results = {}
    
    for model_name, config in MODELS_CONFIG.items():
        print(f"\nðŸ¤– Testando: {model_name}")
        
        # Pula OpenAI se nÃ£o tiver API key
        if config['provider'] == 'openai' and not os.getenv("OPENAI_API_KEY"):
            print("  â­ï¸  Pulando (API key nÃ£o configurada)")
            continue
        
        result = run_analysis(csv_path, config['provider'], config['model'])
        results[model_name] = result
        
        if result['success']:
            print(f"  âœ… Sucesso em {result['time']:.2f}s")
        else:
            print(f"  âŒ Erro: {result['error'][:100]}...")
        
        # Delay entre requests para evitar rate limit
        time.sleep(2)
    
    # Gera markdown
    print("\n\nðŸ“ Gerando relatÃ³rio comparativo...")
    markdown = generate_comparison_markdown(results, csv_filename)
    
    # Salva arquivo
    output_file = Path("docs/MODEL_COMPARISON.md")
    output_file.parent.mkdir(exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown)
    
    print(f"âœ… RelatÃ³rio salvo em: {output_file}")
    print("\n" + "=" * 70)
    print("ðŸŽ‰ ComparaÃ§Ã£o concluÃ­da!")
    print(f"ðŸ“– Visualize o relatÃ³rio: cat {output_file}")

if __name__ == "__main__":
    main()
